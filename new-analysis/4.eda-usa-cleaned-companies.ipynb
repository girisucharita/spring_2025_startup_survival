{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48cc2083",
   "metadata": {},
   "source": [
    "# EDA on uncleaned USA companies\n",
    "Perform initial exploration of the dataset to understand its structure, available features, missing values, and potential target variables for defining \"success\". This step will help us understand what we're working with and how to approach the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16b807a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6bc364f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully with 51637 rows and 19 columns.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# id,Unnamed: 0.1,entity_type,entity_id,parent_id,name,normalized_name,permalink,category_code,status,founded_at,closed_at,domain,homepage_url,twitter_username,logo_url,logo_width,logo_height,short_description,description,overview,tag_list,country_code,state_code,city,region,first_investment_at,last_investment_at,investment_rounds,invested_companies,first_funding_at,last_funding_at,funding_rounds,funding_total_usd,first_milestone_at,last_milestone_at,milestones,relationships,created_by,created_at,updated_at,lat,lng,ROI\n",
    "try:\n",
    "    companies_df = pd.read_csv('/Users/aminosaurier/Downloads/spring_2025_startup_survival/usa_cleaned_companies.csv', sep=',', header=0)\n",
    "    print(f\"Dataset loaded successfully with {companies_df.shape[0]} rows and {companies_df.shape[1]} columns.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b4d48fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 15 rows of the dataset:\n",
      "   entity_type                  name category_code     status  founded_at country_code state_code           city              region first_funding_at last_funding_at  funding_rounds  funding_total_usd first_milestone_at last_milestone_at  milestones  relationships           created_at           updated_at\n",
      "0      Company              Wetpaint           web  operating  2005-10-17          USA         WA        Seattle             Seattle       2005-10-01      2008-05-19            3.00        39750000.00         2010-09-05        2013-09-18        5.00          17.00  2007-05-25 06:51:27  2013-04-13 03:29:00\n",
      "1      Company               Flektor   games_video   acquired         NaN          USA         CA    Culver City         Los Angeles              NaN             NaN             NaN                NaN                NaN               NaN         NaN           6.00  2007-05-31 21:11:51  2008-05-23 23:23:14\n",
      "2      Company                 There   games_video   acquired         NaN          USA         CA      San Mateo              SF Bay              NaN             NaN             NaN                NaN         2003-02-01        2011-09-23        4.00          12.00  2007-08-06 23:52:45  2013-11-04 02:09:48\n",
      "3      Company     Thomas Publishing   advertising  operating         NaN          USA         NY       New York            New York              NaN             NaN             NaN                NaN         1999-06-01        1999-06-01        1.00           2.00  2008-08-24 20:21:21  2009-11-19 17:21:00\n",
      "4      Company       dimension5 labs   advertising  operating  2008-08-01          USA         NM       Santa Fe            Santa Fe              NaN             NaN             NaN                NaN         2008-08-22        2008-08-22        1.00           2.00  2008-08-24 21:54:55  2008-12-21 17:21:53\n",
      "5      Company            FriendFeed           web   acquired  2007-10-01          USA         CA  Mountain View              SF Bay       2008-02-26      2008-02-26            1.00         5000000.00         2008-05-01        2012-09-13        3.00          14.00  2007-10-01 10:17:13  2013-03-13 21:44:15\n",
      "6      Company  PoetryVisualized.com   games_video  operating  2008-01-01          USA         CA         Julian           San Diego              NaN             NaN             NaN                NaN         2008-01-01        2008-01-01        1.00           3.00  2008-08-24 22:21:46  2009-04-03 20:32:21\n",
      "7      Company               Mobclix        mobile   acquired  2008-03-01          USA         CA      Palo Alto              SF Bay       2008-09-01      2008-09-01            1.00                NaN         1995-03-01        2012-09-18        4.00           9.00  2008-08-25 01:32:43  2012-09-22 03:36:21\n",
      "8      Company                Fitbit        health  operating  2007-10-01          USA         CA  San Francisco              SF Bay       2008-10-10      2013-08-13            5.00        68069200.00                NaN               NaN         NaN          14.00  2008-08-25 02:16:54  2013-12-04 09:52:42\n",
      "9      Company                  MTPV     cleantech  operating  2003-01-01          USA         TX         Austin              Austin       2011-03-08      2012-01-26            3.00        10125293.00         2010-01-01        2010-01-01        1.00           6.00  2011-09-07 02:01:00  2013-04-10 04:35:04\n",
      "10     Company            Demandbase     analytics  operating  2006-01-01          USA         CA  San Francisco              SF Bay       2008-08-25      2013-03-28            3.00        33000000.00         2010-05-18        2013-03-01        3.00          19.00  2008-08-25 03:35:42  2013-10-23 11:32:49\n",
      "11     Company              AirSpeed      software  operating  2011-01-01          USA         CA  San Francisco              SF Bay              NaN             NaN             NaN                NaN                NaN               NaN         NaN            NaN  2011-09-07 02:18:41  2012-12-13 04:36:39\n",
      "12     Company      Betts Recruiting    consulting  operating  2009-10-01          USA         NY  San Francisco             unknown              NaN             NaN             NaN                NaN         2009-03-01        2009-03-01        1.00           2.00  2011-09-07 02:43:15  2013-06-10 20:26:20\n",
      "13     Company          Fundable.com       finance  operating  2012-05-22          USA         OH         Powell            Columbus              NaN             NaN             NaN                NaN         2012-04-01        2013-12-11        4.00           3.00  2008-08-25 04:04:26  2013-12-03 12:43:43\n",
      "14     Company             iHireHelp     education  operating  2010-10-01          USA         NJ            NaN  New Jersey - Other       2011-04-16      2011-04-16            1.00          100000.00         2010-10-01        2010-10-01        1.00            NaN  2011-09-07 02:57:58  2011-11-10 22:38:22\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows to understand the data structure\n",
    "print(\"First 15 rows of the dataset:\")\n",
    "print(companies_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6773954d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values analysis:\n",
      "                    Missing Values  Missing Percentage\n",
      "funding_total_usd            33495               64.87\n",
      "first_funding_at             32004               61.98\n",
      "last_funding_at              32004               61.98\n",
      "funding_rounds               31905               61.79\n",
      "last_milestone_at            24967               48.35\n",
      "milestones                   24967               48.35\n",
      "first_milestone_at           24967               48.35\n",
      "relationships                13475               26.10\n",
      "founded_at                   13012               25.20\n",
      "category_code                 4313                8.35\n",
      "city                          1453                2.81\n",
      "state_code                     975                1.89\n",
      "name                             2                0.00\n",
      "entity_type                      0                0.00\n",
      "status                           0                0.00\n",
      "region                           0                0.00\n",
      "country_code                     0                0.00\n",
      "created_at                       0                0.00\n",
      "updated_at                       0                0.00\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = companies_df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(companies_df)) * 100\n",
    "\n",
    "# Create a DataFrame to display missing values information\n",
    "missing_info = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "\n",
    "print(\"\\nMissing values analysis:\")\n",
    "with pd.option_context('display.max_rows', None, 'display.width', 1000):\n",
    "    print(missing_info.sort_values('Missing Percentage', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2886c7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic information about the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51637 entries, 0 to 51636\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   entity_type         51637 non-null  object \n",
      " 1   name                51635 non-null  object \n",
      " 2   category_code       47324 non-null  object \n",
      " 3   status              51637 non-null  object \n",
      " 4   founded_at          38625 non-null  object \n",
      " 5   country_code        51637 non-null  object \n",
      " 6   state_code          50662 non-null  object \n",
      " 7   city                50184 non-null  object \n",
      " 8   region              51637 non-null  object \n",
      " 9   first_funding_at    19633 non-null  object \n",
      " 10  last_funding_at     19633 non-null  object \n",
      " 11  funding_rounds      19732 non-null  float64\n",
      " 12  funding_total_usd   18142 non-null  float64\n",
      " 13  first_milestone_at  26670 non-null  object \n",
      " 14  last_milestone_at   26670 non-null  object \n",
      " 15  milestones          26670 non-null  float64\n",
      " 16  relationships       38162 non-null  float64\n",
      " 17  created_at          51637 non-null  object \n",
      " 18  updated_at          51637 non-null  object \n",
      "dtypes: float64(4), object(15)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check basic information about the dataset\n",
    "print(\"\\nBasic information about the dataset:\")\n",
    "companies_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db31ae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicate_count = companies_df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c64bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types before conversion:\n",
      "entity_type            object\n",
      "name                   object\n",
      "category_code          object\n",
      "status                 object\n",
      "founded_at             object\n",
      "country_code           object\n",
      "state_code             object\n",
      "city                   object\n",
      "region                 object\n",
      "first_funding_at       object\n",
      "last_funding_at        object\n",
      "funding_rounds        float64\n",
      "funding_total_usd     float64\n",
      "first_milestone_at     object\n",
      "last_milestone_at      object\n",
      "milestones            float64\n",
      "relationships         float64\n",
      "created_at             object\n",
      "updated_at             object\n",
      "dtype: object\n",
      "\n",
      "Data types after date conversion:\n",
      "entity_type                   object\n",
      "name                          object\n",
      "category_code                 object\n",
      "status                        object\n",
      "founded_at            datetime64[ns]\n",
      "country_code                  object\n",
      "state_code                    object\n",
      "city                          object\n",
      "region                        object\n",
      "first_funding_at      datetime64[ns]\n",
      "last_funding_at       datetime64[ns]\n",
      "funding_rounds               float64\n",
      "funding_total_usd            float64\n",
      "first_milestone_at    datetime64[ns]\n",
      "last_milestone_at     datetime64[ns]\n",
      "milestones                   float64\n",
      "relationships                float64\n",
      "created_at            datetime64[ns]\n",
      "updated_at            datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Examine data types and convert date columns to datetime format\n",
    "print(\"\\nData types before conversion:\")\n",
    "print(companies_df.dtypes)\n",
    "\n",
    "# Identify date columns\n",
    "date_columns = ['founded_at', 'closed_at', 'first_investment_at', 'last_investment_at', \n",
    "                'first_funding_at', 'last_funding_at', 'first_milestone_at', \n",
    "                'last_milestone_at', 'created_at', 'updated_at']\n",
    "\n",
    "# Convert date columns to datetime\n",
    "for col in date_columns:\n",
    "    if col in companies_df.columns:\n",
    "        companies_df[col] = pd.to_datetime(companies_df[col], errors='coerce')\n",
    "\n",
    "print(\"\\nData types after date conversion:\")\n",
    "print(companies_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dba70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics for numerical columns:\n",
      "       funding_rounds  funding_total_usd  milestones  relationships\n",
      "count        19732.00           18142.00    26670.00       38162.00\n",
      "mean             1.83        16207604.01        1.46           4.95\n",
      "std              1.35        46897804.77        0.77          15.67\n",
      "min              1.00             291.00        1.00           1.00\n",
      "25%              1.00          750000.00        1.00           1.00\n",
      "50%              1.00         3500000.00        1.00           3.00\n",
      "75%              2.00        13950000.00        2.00           5.00\n",
      "max             14.00       833952250.00        9.00        1189.00\n"
     ]
    }
   ],
   "source": [
    "# Generate summary statistics for numerical columns\n",
    "numerical_summary = companies_df.describe(include=[np.number])\n",
    "print(\"\\nSummary statistics for numerical columns:\")\n",
    "print(numerical_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc29e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of categorical columns:\n",
      "          Column  Unique Values     Most Common Value  Most Common Count  Missing Values  Missing Percentage\n",
      "0    entity_type              1               Company              51637               0                0.00\n",
      "1           name          51631  eHealth Technologies                  2               2                0.00\n",
      "2  category_code             42              software               7642            4313                8.35\n",
      "3         status              4             operating              44388               0                0.00\n",
      "4   country_code              1                   USA              51637               0                0.00\n",
      "5     state_code             51                    CA              16447             975                1.89\n",
      "6           city           4311              New York               3809            1453                2.81\n",
      "7         region           1812                SF Bay              10062               0                0.00\n"
     ]
    }
   ],
   "source": [
    "# Analyze categorical columns\n",
    "categorical_columns = companies_df.select_dtypes(include=['object']).columns\n",
    "categorical_summary = pd.DataFrame({\n",
    "    'Column': categorical_columns,\n",
    "    'Unique Values': [companies_df[col].nunique() for col in categorical_columns],\n",
    "    'Most Common Value': [companies_df[col].value_counts().index[0] if not companies_df[col].isna().all() and len(companies_df[col].value_counts()) > 0 else 'N/A' for col in categorical_columns],\n",
    "    'Most Common Count': [companies_df[col].value_counts().iloc[0] if not companies_df[col].isna().all() and len(companies_df[col].value_counts()) > 0 else 0 for col in categorical_columns],\n",
    "    'Missing Values': [companies_df[col].isna().sum() for col in categorical_columns],\n",
    "    'Missing Percentage': [companies_df[col].isna().sum() / len(companies_df) * 100 for col in categorical_columns]\n",
    "})\n",
    "\n",
    "print(\"\\nSummary of categorical columns:\")\n",
    "print(categorical_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbbda6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of company statuses:\n",
      "status\n",
      "operating    44388\n",
      "acquired      4974\n",
      "closed        1354\n",
      "ipo            921\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage distribution of company statuses:\n",
      "status\n",
      "operating   85.96\n",
      "acquired     9.63\n",
      "closed       2.62\n",
      "ipo          1.78\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Analyze the 'status' column\n",
    "if 'status' in companies_df.columns:\n",
    "    status_counts = companies_df['status'].value_counts()\n",
    "    print(\"\\nDistribution of company statuses:\")\n",
    "    print(status_counts)\n",
    "\n",
    "    # Calculate percentage\n",
    "    status_percentage = (status_counts / status_counts.sum() * 100).round(2)\n",
    "    print(\"\\nPercentage distribution of company statuses:\")\n",
    "    print(status_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e46c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 industry categories:\n",
      "category_code\n",
      "software            7642\n",
      "web                 5584\n",
      "other               4293\n",
      "biotech             3001\n",
      "ecommerce           2766\n",
      "advertising         2579\n",
      "mobile              2552\n",
      "enterprise          2063\n",
      "consulting          2006\n",
      "games_video         1954\n",
      "hardware            1419\n",
      "public_relations    1112\n",
      "cleantech           1001\n",
      "network_hosting      921\n",
      "education            850\n",
      "health               720\n",
      "medical              628\n",
      "analytics            596\n",
      "security             566\n",
      "search               561\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Analyze the 'category_code' column to understand industry distribution\n",
    "if 'category_code' in companies_df.columns:\n",
    "    category_counts = companies_df['category_code'].value_counts().head(20)  # Top 20 categories\n",
    "    print(\"\\nTop 20 industry categories:\")\n",
    "    print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd06b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics for funding_rounds:\n",
      "count   19732.00\n",
      "mean        1.83\n",
      "std         1.35\n",
      "min         1.00\n",
      "25%         1.00\n",
      "50%         1.00\n",
      "75%         2.00\n",
      "max        14.00\n",
      "Name: funding_rounds, dtype: float64\n",
      "\n",
      "Summary statistics for funding_total_usd:\n",
      "count       18142.00\n",
      "mean     16207604.01\n",
      "std      46897804.77\n",
      "min           291.00\n",
      "25%        750000.00\n",
      "50%       3500000.00\n",
      "75%      13950000.00\n",
      "max     833952250.00\n",
      "Name: funding_total_usd, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Analyze funding information\n",
    "funding_columns = ['funding_rounds', 'funding_total_usd']\n",
    "for col in funding_columns:\n",
    "    if col in companies_df.columns:\n",
    "        print(f\"\\nSummary statistics for {col}:\")\n",
    "        print(companies_df[col].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b2161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze ROI as a potential target variable\n",
    "if 'ROI' in companies_df.columns:\n",
    "    print(\"\\nSummary statistics for ROI:\")\n",
    "    print(companies_df['ROI'].describe())\n",
    "\n",
    "    # Count non-null ROI values\n",
    "    roi_count = companies_df['ROI'].notna().sum()\n",
    "    print(f\"\\nNumber of companies with ROI data: {roi_count} ({roi_count/len(companies_df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ed89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 country_code values:\n",
      "country_code\n",
      "USA    51637\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 10 state_code values:\n",
      "state_code\n",
      "CA    16447\n",
      "NY     5716\n",
      "MA     2933\n",
      "TX     2802\n",
      "FL     2149\n",
      "WA     1887\n",
      "IL     1736\n",
      "PA     1320\n",
      "NJ     1179\n",
      "CO     1172\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 10 city values:\n",
      "city\n",
      "New York         3809\n",
      "San Francisco    3612\n",
      "Los Angeles      1068\n",
      "Chicago          1025\n",
      "Seattle           936\n",
      "Austin            905\n",
      "San Diego         808\n",
      "Palo Alto         786\n",
      "Boston            675\n",
      "Atlanta           630\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 10 region values:\n",
      "region\n",
      "SF Bay           10062\n",
      "New York          5166\n",
      "Los Angeles       4051\n",
      "Boston            2755\n",
      "Washington DC     1776\n",
      "Seattle           1615\n",
      "Chicago           1608\n",
      "San Diego         1195\n",
      "Atlanta           1044\n",
      "Dallas            1005\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Analyze geographic distribution\n",
    "geo_columns = ['country_code', 'state_code', 'city', 'region']\n",
    "for col in geo_columns:\n",
    "    if col in companies_df.columns and companies_df[col].notna().sum() > 0:\n",
    "        top_locations = companies_df[col].value_counts().head(10)\n",
    "        print(f\"\\nTop 10 {col} values:\")\n",
    "        print(top_locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfbc968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comprehensive column summary created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a comprehensive summary DataFrame for export\n",
    "column_summary = []\n",
    "\n",
    "for column in companies_df.columns:\n",
    "    col_type = companies_df[column].dtype\n",
    "    missing_count = companies_df[column].isna().sum()\n",
    "    missing_pct = (missing_count / len(companies_df)) * 100\n",
    "\n",
    "    if pd.api.types.is_numeric_dtype(companies_df[column]):\n",
    "        unique_count = companies_df[column].nunique()\n",
    "        min_val = companies_df[column].min() if not pd.isna(companies_df[column].min()) else None\n",
    "        max_val = companies_df[column].max() if not pd.isna(companies_df[column].max()) else None\n",
    "        mean_val = companies_df[column].mean() if not pd.isna(companies_df[column].mean()) else None\n",
    "        most_common = None\n",
    "        most_common_count = None\n",
    "    else:\n",
    "        unique_count = companies_df[column].nunique()\n",
    "        min_val = None\n",
    "        max_val = None\n",
    "        mean_val = None\n",
    "        if not companies_df[column].isna().all() and companies_df[column].value_counts().shape[0] > 0:\n",
    "            most_common = str(companies_df[column].value_counts().index[0])\n",
    "            most_common_count = companies_df[column].value_counts().iloc[0]\n",
    "        else:\n",
    "            most_common = None\n",
    "            most_common_count = None\n",
    "\n",
    "    column_summary.append({\n",
    "        'Column': column,\n",
    "        'Data Type': str(col_type),\n",
    "        'Missing Values': missing_count,\n",
    "        'Missing Percentage': missing_pct,\n",
    "        'Unique Values': unique_count,\n",
    "        'Min': min_val,\n",
    "        'Max': max_val,\n",
    "        'Mean': mean_val,\n",
    "        'Most Common Value': most_common,\n",
    "        'Most Common Count': most_common_count\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(column_summary)\n",
    "print(\"\\nComprehensive column summary created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b1b01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics saved to 'usa_cleaned_eda_summary.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the summary to CSV\n",
    "summary_df.to_csv('usa_cleaned_eda_summary.csv', index=False)\n",
    "print(\"Summary statistics saved to 'usa_cleaned_eda_summary.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9cab88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating visualizations for the PDF report...\n",
      "PDF report with 11 pages created successfully.\n",
      "Visualizations saved to 'usa_cleaned_eda_visualizations.pdf'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create visualizations for the PDF report\n",
    "print(\"\\nGenerating visualizations for the PDF report...\")\n",
    "\n",
    "# Function to create visualizations\n",
    "def create_visualizations(df, pdf_path):\n",
    "    with PdfPages(pdf_path) as pdf:\n",
    "        # Set the style for all plots\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "        # 1. Title page\n",
    "        plt.figure(figsize=(8.5, 11))\n",
    "        plt.text(0.5, 0.5, 'Exploratory Data Analysis\\nCrunchbase Companies Dataset', \n",
    "                 horizontalalignment='center', verticalalignment='center', fontsize=24)\n",
    "        plt.text(0.5, 0.4, f'Dataset contains {len(df):,} companies with {df.shape[1]} features', \n",
    "                 horizontalalignment='center', verticalalignment='center', fontsize=16)\n",
    "        plt.axis('off')\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "        # 2. Company status distribution\n",
    "        if 'status' in df.columns:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            status_counts = df['status'].value_counts()\n",
    "            status_counts.plot(kind='bar', color='skyblue')\n",
    "            plt.title('Distribution of Company Statuses')\n",
    "            plt.xlabel('Status')\n",
    "            plt.ylabel('Count')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "            # Pie chart of status\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            status_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90, figsize=(10, 6))\n",
    "            plt.title('Percentage Distribution of Company Statuses')\n",
    "            plt.ylabel('')\n",
    "            plt.tight_layout()\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "        # 3. Category distribution (top 15)\n",
    "        if 'category_code' in df.columns:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            top_categories = df['category_code'].value_counts().head(15)\n",
    "            top_categories.plot(kind='bar', color='lightgreen')\n",
    "            plt.title('Top 15 Industry Categories')\n",
    "            plt.xlabel('Category')\n",
    "            plt.ylabel('Count')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "        # 4. Funding rounds distribution\n",
    "        if 'funding_rounds' in df.columns:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            # Filter out NaN values\n",
    "            funding_data = df['funding_rounds'].dropna()\n",
    "            sns.histplot(funding_data, bins=10, kde=True)\n",
    "            plt.title('Distribution of Funding Rounds')\n",
    "            plt.xlabel('Number of Funding Rounds')\n",
    "            plt.ylabel('Count')\n",
    "            plt.tight_layout()\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "        # 5. Total funding distribution (log scale)\n",
    "        if 'funding_total_usd' in df.columns:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            # Filter out NaN and zero values for log scale\n",
    "            funding_total = df['funding_total_usd'].dropna()\n",
    "            funding_total = funding_total[funding_total > 0]\n",
    "\n",
    "            if len(funding_total) > 0:\n",
    "                plt.hist(np.log10(funding_total), bins=20, color='salmon')\n",
    "                plt.title('Distribution of Total Funding (Log Scale)')\n",
    "                plt.xlabel('Log10(Total Funding in USD)')\n",
    "                plt.ylabel('Count')\n",
    "                plt.tight_layout()\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "\n",
    "        # 6. ROI distribution\n",
    "        if 'ROI' in df.columns:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            roi_data = df['ROI'].dropna()\n",
    "\n",
    "            if len(roi_data) > 0:\n",
    "                sns.histplot(roi_data, bins=20, kde=True)\n",
    "                plt.title('Distribution of ROI')\n",
    "                plt.xlabel('ROI')\n",
    "                plt.ylabel('Count')\n",
    "                plt.tight_layout()\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "\n",
    "                # ROI boxplot\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                sns.boxplot(x=roi_data)\n",
    "                plt.title('Boxplot of ROI')\n",
    "                plt.xlabel('ROI')\n",
    "                plt.tight_layout()\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "\n",
    "        # 7. Geographic distribution - Countries\n",
    "        if 'country_code' in df.columns:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            top_countries = df['country_code'].value_counts().head(10)\n",
    "            top_countries.plot(kind='bar', color='lightblue')\n",
    "            plt.title('Top 10 Countries')\n",
    "            plt.xlabel('Country Code')\n",
    "            plt.ylabel('Count')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "        # 8. Company founding years distribution\n",
    "        if 'founded_at' in df.columns:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            # Extract year from founded_at\n",
    "            founded_years = df['founded_at'].dropna().dt.year\n",
    "\n",
    "            if len(founded_years) > 0:\n",
    "                plt.hist(founded_years, bins=30, color='lightgreen')\n",
    "                plt.title('Distribution of Company Founding Years')\n",
    "                plt.xlabel('Year')\n",
    "                plt.ylabel('Count')\n",
    "                plt.tight_layout()\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "\n",
    "        # 9. Missing values visualization\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        missing_data = df.isnull().sum() / len(df) * 100\n",
    "        missing_data = missing_data[missing_data > 0].sort_values(ascending=False)\n",
    "\n",
    "        if len(missing_data) > 0:\n",
    "            missing_data.plot(kind='bar', color='coral')\n",
    "            plt.title('Percentage of Missing Values by Column')\n",
    "            plt.xlabel('Columns')\n",
    "            plt.ylabel('Percentage Missing')\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.tight_layout()\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "        # 10. Correlation heatmap for numerical columns\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        numerical_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "        # Drop columns with all NaN values\n",
    "        numerical_df = numerical_df.dropna(axis=1, how='all')\n",
    "\n",
    "        if numerical_df.shape[1] > 1:  # Only create heatmap if we have at least 2 numerical columns\n",
    "            correlation = numerical_df.corr()\n",
    "            mask = np.triu(np.ones_like(correlation, dtype=bool))\n",
    "            sns.heatmap(correlation, mask=mask, annot=True, fmt=\".2f\", cmap='coolwarm', \n",
    "                        linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
    "            plt.title('Correlation Heatmap of Numerical Features')\n",
    "            plt.tight_layout()\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "        # 11. Relationship between funding and ROI (if both exist)\n",
    "        if 'funding_total_usd' in df.columns and 'ROI' in df.columns:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            # Filter for non-null values in both columns\n",
    "            funding_roi_df = df[['funding_total_usd', 'ROI']].dropna()\n",
    "\n",
    "            if len(funding_roi_df) > 0:\n",
    "                # For better visualization, filter out extreme values\n",
    "                q_low = funding_roi_df['ROI'].quantile(0.01)\n",
    "                q_high = funding_roi_df['ROI'].quantile(0.99)\n",
    "                filtered_df = funding_roi_df[(funding_roi_df['ROI'] >= q_low) & \n",
    "                                            (funding_roi_df['ROI'] <= q_high) & \n",
    "                                            (funding_roi_df['funding_total_usd'] > 0)]\n",
    "\n",
    "                if len(filtered_df) > 0:\n",
    "                    plt.scatter(np.log10(filtered_df['funding_total_usd']), filtered_df['ROI'], alpha=0.5)\n",
    "                    plt.title('Relationship Between Total Funding and ROI')\n",
    "                    plt.xlabel('Log10(Total Funding in USD)')\n",
    "                    plt.ylabel('ROI')\n",
    "                    plt.tight_layout()\n",
    "                    pdf.savefig()\n",
    "                    plt.close()\n",
    "\n",
    "        # 12. Status by category (top 10 categories)\n",
    "        if 'category_code' in df.columns and 'status' in df.columns:\n",
    "            plt.figure(figsize=(14, 8))\n",
    "            # Get top 10 categories\n",
    "            top_cats = df['category_code'].value_counts().head(10).index\n",
    "\n",
    "            # Filter for those categories\n",
    "            cat_status_df = df[df['category_code'].isin(top_cats)]\n",
    "\n",
    "            if len(cat_status_df) > 0:\n",
    "                # Create a crosstab\n",
    "                cat_status = pd.crosstab(cat_status_df['category_code'], cat_status_df['status'])\n",
    "\n",
    "                # Plot stacked bar chart\n",
    "                cat_status.plot(kind='bar', stacked=True, figsize=(14, 8))\n",
    "                plt.title('Company Status by Top 10 Categories')\n",
    "                plt.xlabel('Category')\n",
    "                plt.ylabel('Count')\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.legend(title='Status')\n",
    "                plt.tight_layout()\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "\n",
    "        print(f\"PDF report with {pdf.get_pagecount()} pages created successfully.\")\n",
    "\n",
    "# Create the visualizations PDF\n",
    "create_visualizations(companies_df, 'usa_cleaned_eda_visualizations.pdf')\n",
    "print(\"Visualizations saved to 'usa_cleaned_eda_visualizations.pdf'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414bc669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY OF INITIAL DATA EXPLORATION ===\n",
      "Total number of companies in the dataset: 51637\n",
      "Total number of features: 19\n",
      "\n",
      "Company Status Distribution:\n",
      "  - operating: 44388 companies (85.96%)\n",
      "  - acquired: 4974 companies (9.63%)\n",
      "  - closed: 1354 companies (2.62%)\n",
      "  - ipo: 921 companies (1.78%)\n",
      "\n",
      "Funding Summary:\n",
      "  - Companies with funding data: 18142 (35.13%)\n",
      "  - Average funding amount: $16,207,604.01\n",
      "\n",
      "Geographic Summary:\n",
      "  - Companies with country data: 51637 (100.00%)\n",
      "  - Most common country: USA with 51637 companies\n",
      "\n",
      "Potential target variables for defining 'success':\n",
      "  1. Status (e.g., 'acquired', 'ipo' as success indicators)\n",
      "  2. ROI (Return on Investment)\n",
      "  3. Funding amount (total funding raised)\n",
      "  4. Longevity (time between founding and current/closing date)\n",
      "  5. Combination of the above factors\n",
      "\n",
      "EDA completed successfully. Results saved to 'usa_cleaned_eda_summary.csv' and 'usa_cleaned_eda_visualizations.pdf'\n"
     ]
    }
   ],
   "source": [
    "# Final summary of findings\n",
    "print(\"\\n=== SUMMARY OF INITIAL DATA EXPLORATION ===\")\n",
    "print(f\"Total number of companies in the dataset: {companies_df.shape[0]}\")\n",
    "print(f\"Total number of features: {companies_df.shape[1]}\")\n",
    "\n",
    "# Count companies by status\n",
    "if 'status' in companies_df.columns:\n",
    "    print(\"\\nCompany Status Distribution:\")\n",
    "    for status, count in companies_df['status'].value_counts().items():\n",
    "        print(f\"  - {status}: {count} companies ({count/len(companies_df)*100:.2f}%)\")\n",
    "\n",
    "# Funding summary\n",
    "if 'funding_total_usd' in companies_df.columns:\n",
    "    funded_companies = companies_df['funding_total_usd'].notna().sum()\n",
    "    avg_funding = companies_df['funding_total_usd'].mean()\n",
    "    print(f\"\\nFunding Summary:\")\n",
    "    print(f\"  - Companies with funding data: {funded_companies} ({funded_companies/len(companies_df)*100:.2f}%)\")\n",
    "    print(f\"  - Average funding amount: ${avg_funding:,.2f}\")\n",
    "\n",
    "# ROI summary\n",
    "if 'ROI' in companies_df.columns:\n",
    "    roi_companies = companies_df['ROI'].notna().sum()\n",
    "    avg_roi = companies_df['ROI'].mean()\n",
    "    print(f\"\\nROI Summary:\")\n",
    "    print(f\"  - Companies with ROI data: {roi_companies} ({roi_companies/len(companies_df)*100:.2f}%)\")\n",
    "    print(f\"  - Average ROI: {avg_roi:.2f}\")\n",
    "\n",
    "# Geographic summary\n",
    "if 'country_code' in companies_df.columns:\n",
    "    countries = companies_df['country_code'].notna().sum()\n",
    "    top_country = companies_df['country_code'].value_counts().index[0] if companies_df['country_code'].value_counts().shape[0] > 0 else \"Unknown\"\n",
    "    top_country_count = companies_df['country_code'].value_counts().iloc[0] if companies_df['country_code'].value_counts().shape[0] > 0 else 0\n",
    "    print(f\"\\nGeographic Summary:\")\n",
    "    print(f\"  - Companies with country data: {countries} ({countries/len(companies_df)*100:.2f}%)\")\n",
    "    print(f\"  - Most common country: {top_country} with {top_country_count} companies\")\n",
    "\n",
    "print(\"\\nPotential target variables for defining 'success':\")\n",
    "print(\"  1. Status (e.g., 'acquired', 'ipo' as success indicators)\")\n",
    "print(\"  2. ROI (Return on Investment)\")\n",
    "print(\"  3. Funding amount (total funding raised)\")\n",
    "print(\"  4. Longevity (time between founding and current/closing date)\")\n",
    "print(\"  5. Combination of the above factors\")\n",
    "\n",
    "print(\"\\nEDA completed successfully. Results saved to 'usa_cleaned_eda_summary.csv' and 'usa_cleaned_eda_visualizations.pdf'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47dfcf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
