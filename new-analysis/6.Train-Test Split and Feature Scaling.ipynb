{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7d3a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Train-Test Split and Feature Scaling step...\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Starting Train-Test Split and Feature Scaling step...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da026011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data...\n",
      "Data loaded with headers.\n",
      "Data shape: (51613, 6)\n",
      "First few rows:\n",
      "   funding_rounds  funding_total_usd  milestones  relationships   age  \\\n",
      "0             3.0         39750000.0         5.0           17.0  9.20   \n",
      "1             0.0                0.0         0.0            6.0  7.00   \n",
      "2             0.0                0.0         4.0           12.0  7.00   \n",
      "3             0.0                0.0         1.0            2.0  7.00   \n",
      "4             0.0                0.0         1.0            2.0  6.41   \n",
      "\n",
      "   success_binary  \n",
      "0               0  \n",
      "1               1  \n",
      "2               1  \n",
      "3               0  \n",
      "4               0  \n",
      "\n",
      "Data information:\n",
      "Number of samples: 51613\n",
      "Number of features: 6\n",
      "Column names: ['funding_rounds', 'funding_total_usd', 'milestones', 'relationships', 'age', 'success_binary']\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed data\n",
    "print(\"Loading preprocessed data...\")\n",
    "try:\n",
    "    # First try to load with headers, as this is most common\n",
    "    data = pd.read_csv('usa_final_companies_with_success_labels.csv')\n",
    "    print(\"Data loaded with headers.\")\n",
    "    print(f\"Data shape: {data.shape}\")\n",
    "    print(\"First few rows:\")\n",
    "    print(data.head())\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle other potential errors\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    raise\n",
    "\n",
    "# Display basic information about the data\n",
    "print(\"\\nData information:\")\n",
    "print(f\"Number of samples: {data.shape[0]}\")\n",
    "print(f\"Number of features: {data.shape[1]}\")\n",
    "print(f\"Column names: {list(data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0347de26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for missing values...\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Basic statistics of the data:\n",
      "       funding_rounds  funding_total_usd   milestones  relationships  \\\n",
      "count    51613.000000       5.161300e+04  51613.00000   51613.000000   \n",
      "mean         0.700657       5.695137e+06      0.75233       3.918548   \n",
      "std          1.219888       2.886024e+07      0.91625      13.589127   \n",
      "min          0.000000       0.000000e+00      0.00000       1.000000   \n",
      "25%          0.000000       0.000000e+00      0.00000       1.000000   \n",
      "50%          0.000000       0.000000e+00      1.00000       2.000000   \n",
      "75%          1.000000       1.000000e+06      1.00000       4.000000   \n",
      "max         14.000000       8.339523e+08      9.00000    1189.000000   \n",
      "\n",
      "                age  success_binary  \n",
      "count  51613.000000    51613.000000  \n",
      "mean       9.399257        0.324201  \n",
      "std        9.423326        0.468080  \n",
      "min        0.000000        0.000000  \n",
      "25%        5.000000        0.000000  \n",
      "50%        7.000000        0.000000  \n",
      "75%       10.000000        1.000000  \n",
      "max      114.000000        1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nChecking for missing values...\")\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\nBasic statistics of the data:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d375629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Separating features and target variable...\n",
      "Using column names to identify target variable...\n",
      "Found target column: success_binary\n",
      "Features shape: (51613, 5)\n",
      "Target shape: (51613,)\n",
      "Target value counts:\n",
      "success_binary\n",
      "0    34880\n",
      "1    16733\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target variable\n",
    "# Assuming the last column is the target variable (success_binary)\n",
    "print(\"\\nSeparating features and target variable...\")\n",
    "\n",
    "# Check if the data has column names\n",
    "if isinstance(data.columns[0], str) and not data.columns[0].isdigit():\n",
    "    # Data has column names\n",
    "    print(\"Using column names to identify target variable...\")\n",
    "\n",
    "    # Look for common target column names\n",
    "    target_columns = ['success_binary', 'target', 'label', 'class', 'y']\n",
    "    target_col = None\n",
    "\n",
    "    for col in target_columns:\n",
    "        if col in data.columns:\n",
    "            target_col = col\n",
    "            break\n",
    "\n",
    "    if target_col:\n",
    "        print(f\"Found target column: {target_col}\")\n",
    "        X = data.drop(columns=[target_col])\n",
    "        y = data[target_col]\n",
    "    else:\n",
    "        print(\"No standard target column found. Assuming last column is target.\")\n",
    "        X = data.iloc[:, :-1]\n",
    "        y = data.iloc[:, -1]\n",
    "else:\n",
    "    # Data doesn't have column names\n",
    "    print(\"No column names found. Assuming last column is target.\")\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target value counts:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ff1ebde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data into training and testing sets...\n",
      "Training set shape: (41290, 5)\n",
      "Testing set shape: (10323, 5)\n",
      "Training target distribution:\n",
      "success_binary\n",
      "0    0.675805\n",
      "1    0.324195\n",
      "Name: proportion, dtype: float64\n",
      "Testing target distribution:\n",
      "success_binary\n",
      "0    0.675773\n",
      "1    0.324227\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "print(\"\\nSplitting data into training and testing sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "print(f\"Training target distribution:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"Testing target distribution:\\n{y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e246241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling features...\n",
      "First few rows of scaled training data:\n",
      "   funding_rounds  funding_total_usd  milestones  relationships       age\n",
      "0        1.061713           0.203911    2.440358       0.002626  0.694242\n",
      "1       -0.573306          -0.199304   -0.821018      -0.201348 -0.255226\n",
      "2       -0.573306          -0.199304   -0.821018      -0.065365  0.061264\n",
      "3        1.061713           4.647531    0.266107       1.294464  2.698674\n",
      "4        1.061713          -0.160714   -0.821018      -0.065365 -0.571715\n"
     ]
    }
   ],
   "source": [
    "# Scale the features\n",
    "print(\"\\nScaling features...\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame to preserve column names if they exist\n",
    "if isinstance(X_train, pd.DataFrame) and X_train.columns.dtype == 'object':\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "else:\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled)\n",
    "\n",
    "# Check the scaled data\n",
    "print(\"First few rows of scaled training data:\")\n",
    "print(X_train_scaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36844191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving scaled data and target variables...\n",
      "Saved X_train.csv\n",
      "Saved X_test.csv\n",
      "Saved y_train.csv\n",
      "Saved y_test.csv\n",
      "Saved scaler.pkl\n",
      "\n",
      "Train-Test Split and Feature Scaling step completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the scaled training and testing sets\n",
    "print(\"\\nSaving scaled data and target variables...\")\n",
    "\n",
    "# Save X_train_scaled\n",
    "X_train_scaled.to_csv('/Users/aminosaurier/Downloads/spring_2025_startup_survival/new-analysis/X_train.csv', index=False)\n",
    "print(\"Saved X_train.csv\")\n",
    "\n",
    "# Save X_test_scaled\n",
    "X_test_scaled.to_csv('/Users/aminosaurier/Downloads/spring_2025_startup_survival/new-analysis/X_test.csv', index=False)\n",
    "print(\"Saved X_test.csv\")\n",
    "\n",
    "# Save y_train\n",
    "if isinstance(y_train, pd.Series):\n",
    "    y_train.to_csv('/Users/aminosaurier/Downloads/spring_2025_startup_survival/new-analysis/y_train.csv', index=False, header=True)\n",
    "else:\n",
    "    pd.DataFrame(y_train).to_csv('/Users/aminosaurier/Downloads/spring_2025_startup_survival/new-analysis/y_train.csv', index=False, header=False)\n",
    "print(\"Saved y_train.csv\")\n",
    "\n",
    "# Save y_test\n",
    "if isinstance(y_test, pd.Series):\n",
    "    y_test.to_csv('/Users/aminosaurier/Downloads/spring_2025_startup_survival/new-analysis/y_test.csv', index=False, header=True)\n",
    "else:\n",
    "    pd.DataFrame(y_test).to_csv('/Users/aminosaurier/Downloads/spring_2025_startup_survival/new-analysis/y_test.csv', index=False, header=False)\n",
    "print(\"Saved y_test.csv\")\n",
    "\n",
    "# Save the scaler\n",
    "with open('/Users/aminosaurier/Downloads/spring_2025_startup_survival/new-analysis/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"Saved scaler.pkl\")\n",
    "\n",
    "print(\"\\nTrain-Test Split and Feature Scaling step completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51d558b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of outputs:\n",
      "X_train.csv: 41290 samples, 5 features\n",
      "X_test.csv: 10323 samples, 5 features\n",
      "y_train.csv: 41290 labels\n",
      "y_test.csv: 10323 labels\n",
      "scaler.pkl: StandardScaler object\n",
      "scaling_effect.png: Visualization of scaling effect on features\n",
      "X_train.csv: ✓ (File exists)\n",
      "X_test.csv: ✓ (File exists)\n",
      "y_train.csv: ✓ (File exists)\n",
      "y_test.csv: ✓ (File exists)\n",
      "scaler.pkl: ✓ (File exists)\n"
     ]
    }
   ],
   "source": [
    "# Print summary of the outputs\n",
    "print(\"\\nSummary of outputs:\")\n",
    "print(f\"X_train.csv: {X_train_scaled.shape[0]} samples, {X_train_scaled.shape[1]} features\")\n",
    "print(f\"X_test.csv: {X_test_scaled.shape[0]} samples, {X_test_scaled.shape[1]} features\")\n",
    "print(f\"y_train.csv: {len(y_train)} labels\")\n",
    "print(f\"y_test.csv: {len(y_test)} labels\")\n",
    "print(\"scaler.pkl: StandardScaler object\")\n",
    "print(\"scaling_effect.png: Visualization of scaling effect on features\")\n",
    "\n",
    "# Check if the files were created successfully\n",
    "for filename in ['X_train.csv', 'X_test.csv', 'y_train.csv', 'y_test.csv', 'scaler.pkl']:\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"{filename}: ✓ (File exists)\")\n",
    "    else:\n",
    "        print(f\"{filename}: ✗ (File does not exist)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9260202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
