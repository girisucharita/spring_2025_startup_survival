{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7d3a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Train-Test Split and Feature Scaling step...\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Starting Train-Test Split and Feature Scaling step...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da026011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data...\n",
      "Data loaded with headers.\n",
      "Data shape: (51637, 26)\n",
      "First few rows:\n",
      "  entity_type               name category_code     status  founded_at  \\\n",
      "0     Company           Wetpaint           web  operating  2005-10-17   \n",
      "1     Company            Flektor   games_video   acquired         NaN   \n",
      "2     Company              There   games_video   acquired         NaN   \n",
      "3     Company  Thomas Publishing   advertising  operating         NaN   \n",
      "4     Company    dimension5 labs   advertising  operating  2008-08-01   \n",
      "\n",
      "  country_code state_code         city       region first_funding_at  ...  \\\n",
      "0          USA         WA      Seattle      Seattle       2005-10-01  ...   \n",
      "1          USA         CA  Culver City  Los Angeles              NaN  ...   \n",
      "2          USA         CA    San Mateo       SF Bay              NaN  ...   \n",
      "3          USA         NY     New York     New York              NaN  ...   \n",
      "4          USA         NM     Santa Fe     Santa Fe              NaN  ...   \n",
      "\n",
      "  relationships           created_at           updated_at  age_years  \\\n",
      "0          17.0  2007-05-25 06:51:27  2013-04-13 03:29:00  17.207392   \n",
      "1           6.0  2007-05-31 21:11:51  2008-05-23 23:23:14        NaN   \n",
      "2          12.0  2007-08-06 23:52:45  2013-11-04 02:09:48        NaN   \n",
      "3           2.0  2008-08-24 20:21:21  2009-11-19 17:21:00        NaN   \n",
      "4           2.0  2008-08-24 21:54:55  2008-12-21 17:21:53  14.417522   \n",
      "\n",
      "  success_status  success_funding  success_age success_score success_binary  \\\n",
      "0              0                1            0             1              1   \n",
      "1              1                0            0             3              1   \n",
      "2              1                0            0             3              1   \n",
      "3              0                0            0             0              0   \n",
      "4              0                0            0             0              0   \n",
      "\n",
      "   success_class  \n",
      "0    low_success  \n",
      "1   high_success  \n",
      "2   high_success  \n",
      "3   unsuccessful  \n",
      "4   unsuccessful  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "Data information:\n",
      "Number of samples: 51637\n",
      "Number of features: 26\n",
      "Column names: ['entity_type', 'name', 'category_code', 'status', 'founded_at', 'country_code', 'state_code', 'city', 'region', 'first_funding_at', 'last_funding_at', 'funding_rounds', 'funding_total_usd', 'first_milestone_at', 'last_milestone_at', 'milestones', 'relationships', 'created_at', 'updated_at', 'age_years', 'success_status', 'success_funding', 'success_age', 'success_score', 'success_binary', 'success_class']\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed data\n",
    "print(\"Loading preprocessed data...\")\n",
    "try:\n",
    "    # First try to load with headers, as this is most common\n",
    "    data = pd.read_csv('/Users/aminosaurier/Downloads/spring_2025_startup_survival/new-analysis/usa_companies_with_success_labels.csv')\n",
    "    print(\"Data loaded with headers.\")\n",
    "    print(f\"Data shape: {data.shape}\")\n",
    "    print(\"First few rows:\")\n",
    "    print(data.head())\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle other potential errors\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    raise\n",
    "\n",
    "# Display basic information about the data\n",
    "print(\"\\nData information:\")\n",
    "print(f\"Number of samples: {data.shape[0]}\")\n",
    "print(f\"Number of features: {data.shape[1]}\")\n",
    "print(f\"Column names: {list(data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0347de26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for missing values...\n",
      "name                      2\n",
      "category_code          4313\n",
      "founded_at            13012\n",
      "state_code              975\n",
      "city                   1453\n",
      "first_funding_at      32004\n",
      "last_funding_at       32004\n",
      "funding_rounds        31905\n",
      "funding_total_usd     33495\n",
      "first_milestone_at    24967\n",
      "last_milestone_at     24967\n",
      "milestones            24967\n",
      "relationships         13475\n",
      "age_years             13012\n",
      "dtype: int64\n",
      "\n",
      "Basic statistics of the data:\n",
      "       funding_rounds  funding_total_usd    milestones  relationships  \\\n",
      "count    19732.000000       1.814200e+04  26670.000000   38162.000000   \n",
      "mean         1.833773       1.711986e+07      1.456655       4.948561   \n",
      "std          1.347464       7.802633e+07      0.774161      15.674637   \n",
      "min          1.000000       2.910000e+02      1.000000       1.000000   \n",
      "25%          1.000000       7.500000e+05      1.000000       1.000000   \n",
      "50%          1.000000       3.500000e+06      1.000000       3.000000   \n",
      "75%          2.000000       1.395000e+07      2.000000       5.000000   \n",
      "max         14.000000       5.700000e+09      9.000000    1189.000000   \n",
      "\n",
      "          age_years  success_status  success_funding   success_age  \\\n",
      "count  38625.000000    51637.000000     51637.000000  51637.000000   \n",
      "mean      18.295021        0.114162         0.087863      0.189903   \n",
      "std       10.742807        0.318011         0.283099      0.392228   \n",
      "min        8.999316        0.000000         0.000000      0.000000   \n",
      "25%       12.167009        0.000000         0.000000      0.000000   \n",
      "50%       15.000684        0.000000         0.000000      0.000000   \n",
      "75%       20.999316        0.000000         0.000000      0.000000   \n",
      "max      121.998631        1.000000         1.000000      1.000000   \n",
      "\n",
      "       success_score  success_binary  \n",
      "count   51637.000000    51637.000000  \n",
      "mean        0.655441        0.314368  \n",
      "std         1.206950        0.464268  \n",
      "min         0.000000        0.000000  \n",
      "25%         0.000000        0.000000  \n",
      "50%         0.000000        0.000000  \n",
      "75%         1.000000        1.000000  \n",
      "max         6.000000        1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nChecking for missing values...\")\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\nBasic statistics of the data:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d375629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Separating features and target variable...\n",
      "Using column names to identify target variable...\n",
      "Found target column: success_binary\n",
      "Features shape: (51637, 25)\n",
      "Target shape: (51637,)\n",
      "Target value counts:\n",
      "success_binary\n",
      "0    35404\n",
      "1    16233\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target variable\n",
    "# Assuming the last column is the target variable (success_binary)\n",
    "print(\"\\nSeparating features and target variable...\")\n",
    "\n",
    "# Check if the data has column names\n",
    "if isinstance(data.columns[0], str) and not data.columns[0].isdigit():\n",
    "    # Data has column names\n",
    "    print(\"Using column names to identify target variable...\")\n",
    "\n",
    "    # Look for common target column names\n",
    "    target_columns = ['success_binary', 'target', 'label', 'class', 'y']\n",
    "    target_col = None\n",
    "\n",
    "    for col in target_columns:\n",
    "        if col in data.columns:\n",
    "            target_col = col\n",
    "            break\n",
    "\n",
    "    if target_col:\n",
    "        print(f\"Found target column: {target_col}\")\n",
    "        X = data.drop(columns=[target_col])\n",
    "        y = data[target_col]\n",
    "    else:\n",
    "        print(\"No standard target column found. Assuming last column is target.\")\n",
    "        X = data.iloc[:, :-1]\n",
    "        y = data.iloc[:, -1]\n",
    "else:\n",
    "    # Data doesn't have column names\n",
    "    print(\"No column names found. Assuming last column is target.\")\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target value counts:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ff1ebde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data into training and testing sets...\n",
      "Training set shape: (41309, 25)\n",
      "Testing set shape: (10328, 25)\n",
      "Training target distribution:\n",
      "success_binary\n",
      "0    0.685638\n",
      "1    0.314362\n",
      "Name: proportion, dtype: float64\n",
      "Testing target distribution:\n",
      "success_binary\n",
      "0    0.685612\n",
      "1    0.314388\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "print(\"\\nSplitting data into training and testing sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "print(f\"Training target distribution:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"Testing target distribution:\\n{y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e246241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling features...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Company'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3p/cl9ydhvx20s11tty79_893580000gn/T/ipykernel_4559/3106499488.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nScaling features...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Fit the scaler on the training data and transform both training and testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Convert back to DataFrame to preserve column names if they exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             return_tuple = (\n",
      "\u001b[0;32m/opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    914\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \"\"\"\n\u001b[1;32m    892\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1385\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1386\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \"\"\"\n\u001b[1;32m    929\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2940\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2947\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1052\u001b[0m                         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m                 raise ValueError(\n\u001b[1;32m   1058\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m                 \u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Company'"
     ]
    }
   ],
   "source": [
    "# # Scale the features\n",
    "# print(\"\\nScaling features...\")\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Fit the scaler on the training data and transform both training and testing data\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # Convert back to DataFrame to preserve column names if they exist\n",
    "# if isinstance(X_train, pd.DataFrame) and X_train.columns.dtype == 'object':\n",
    "#     X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "#     X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "# else:\n",
    "#     X_train_scaled = pd.DataFrame(X_train_scaled)\n",
    "#     X_test_scaled = pd.DataFrame(X_test_scaled)\n",
    "\n",
    "# # Check the scaled data\n",
    "# print(\"First few rows of scaled training data:\")\n",
    "# print(X_train_scaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ccb7d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling numerical features only...\n",
      "First few rows of scaled training data:\n",
      "      entity_type                 name category_code     status  founded_at  \\\n",
      "26227     Company          Culture Jam           web  operating  2008-07-01   \n",
      "8193      Company              Namella   advertising  operating  2011-10-01   \n",
      "48112     Company      Unique Contacts   advertising  operating  2008-11-10   \n",
      "44574     Company    EVida Power, Inc.     cleantech  operating  2008-01-01   \n",
      "8804      Company  Elusys Therapeutics       biotech  operating         NaN   \n",
      "\n",
      "      country_code state_code           city          region first_funding_at  \\\n",
      "26227          USA         CA    Los Angeles     Los Angeles       2008-07-01   \n",
      "8193           USA         CA     Costa Mesa     Los Angeles              NaN   \n",
      "48112          USA         NV            NaN  Nevada - Other              NaN   \n",
      "44574          USA         CA  San Francisco          SF Bay              NaN   \n",
      "8804           USA         NJ     Pine Brook      Pine Brook              NaN   \n",
      "\n",
      "       ... milestones  relationships           created_at  \\\n",
      "26227  ...   1.994814      -0.132952  2009-07-07 01:15:41   \n",
      "8193   ...        NaN      -0.132952  2012-07-11 14:56:18   \n",
      "48112  ...        NaN            NaN  2011-05-09 17:42:09   \n",
      "44574  ...        NaN      -0.062286  2011-01-05 15:21:16   \n",
      "8804   ...   0.703831      -0.203618  2012-08-03 13:25:42   \n",
      "\n",
      "                updated_at age_years  success_status  success_funding  \\\n",
      "26227  2013-03-26 03:47:27 -0.351542       -0.360454        -0.309308   \n",
      "8193   2013-06-06 19:57:07 -0.652486       -0.360454        -0.309308   \n",
      "48112  2012-01-24 05:04:38 -0.385008       -0.360454        -0.309308   \n",
      "44574  2011-01-14 05:03:00 -0.305398       -0.360454        -0.309308   \n",
      "8804   2012-08-03 13:28:03       NaN       -0.360454        -0.309308   \n",
      "\n",
      "      success_age success_score  success_class  \n",
      "26227   -0.483457     -0.543232   unsuccessful  \n",
      "8193    -0.483457     -0.543232   unsuccessful  \n",
      "48112   -0.483457     -0.543232   unsuccessful  \n",
      "44574   -0.483457     -0.543232   unsuccessful  \n",
      "8804    -0.483457     -0.543232   unsuccessful  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Scale the features\n",
    "print(\"\\nScaling numerical features only...\")\n",
    "\n",
    "# Identify numerical columns\n",
    "numeric_columns = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on training data's numeric columns\n",
    "X_train_scaled_numeric = scaler.fit_transform(X_train[numeric_columns])\n",
    "\n",
    "# Apply the same transformation to test data\n",
    "X_test_scaled_numeric = scaler.transform(X_test[numeric_columns])\n",
    "\n",
    "# Copy original DataFrames to preserve non-numeric columns\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# Replace numeric columns with their scaled versions\n",
    "X_train_scaled[numeric_columns] = X_train_scaled_numeric\n",
    "X_test_scaled[numeric_columns] = X_test_scaled_numeric\n",
    "\n",
    "# Check the scaled data\n",
    "print(\"First few rows of scaled training data:\")\n",
    "print(X_train_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36844191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving scaled data and target variables...\n",
      "Saved X_train.csv\n",
      "Saved X_test.csv\n",
      "Saved y_train.csv\n",
      "Saved y_test.csv\n",
      "Saved scaler.pkl\n",
      "\n",
      "Train-Test Split and Feature Scaling step completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the scaled training and testing sets\n",
    "print(\"\\nSaving scaled data and target variables...\")\n",
    "\n",
    "# Save X_train_scaled\n",
    "X_train_scaled.to_csv('/Users/aminosaurier/Downloads/spring_2025_startup_survival/new-analysis/X_train.csv', index=False)\n",
    "print(\"Saved X_train.csv\")\n",
    "\n",
    "# Save X_test_scaled\n",
    "X_test_scaled.to_csv('/Users/aminosaurier/Downloads/spring_2025_startup_survival/new-analysis/X_test.csv', index=False)\n",
    "print(\"Saved X_test.csv\")\n",
    "\n",
    "# Save y_train\n",
    "if isinstance(y_train, pd.Series):\n",
    "    y_train.to_csv('/Users/aminosaurier/Downloads/spring_2025_startup_survival/new-analysis/y_train.csv', index=False, header=True)\n",
    "else:\n",
    "    pd.DataFrame(y_train).to_csv('/Users/aminosaurier/Downloads/spring_2025_startup_survival/new-analysis/y_train.csv', index=False, header=False)\n",
    "print(\"Saved y_train.csv\")\n",
    "\n",
    "# Save y_test\n",
    "if isinstance(y_test, pd.Series):\n",
    "    y_test.to_csv('/Users/aminosaurier/Downloads/spring_2025_startup_survival/new-analysis/y_test.csv', index=False, header=True)\n",
    "else:\n",
    "    pd.DataFrame(y_test).to_csv('/Users/aminosaurier/Downloads/spring_2025_startup_survival/new-analysis/y_test.csv', index=False, header=False)\n",
    "print(\"Saved y_test.csv\")\n",
    "\n",
    "# Save the scaler\n",
    "with open('/Users/aminosaurier/Downloads/spring_2025_startup_survival/new-analysis/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"Saved scaler.pkl\")\n",
    "\n",
    "print(\"\\nTrain-Test Split and Feature Scaling step completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51d558b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of outputs:\n",
      "X_train.csv: 41309 samples, 25 features\n",
      "X_test.csv: 10328 samples, 25 features\n",
      "y_train.csv: 41309 labels\n",
      "y_test.csv: 10328 labels\n",
      "scaler.pkl: StandardScaler object\n",
      "scaling_effect.png: Visualization of scaling effect on features\n",
      "X_train.csv: ✗ (File does not exist)\n",
      "X_test.csv: ✗ (File does not exist)\n",
      "y_train.csv: ✗ (File does not exist)\n",
      "y_test.csv: ✗ (File does not exist)\n",
      "scaler.pkl: ✗ (File does not exist)\n"
     ]
    }
   ],
   "source": [
    "# Print summary of the outputs\n",
    "print(\"\\nSummary of outputs:\")\n",
    "print(f\"X_train.csv: {X_train_scaled.shape[0]} samples, {X_train_scaled.shape[1]} features\")\n",
    "print(f\"X_test.csv: {X_test_scaled.shape[0]} samples, {X_test_scaled.shape[1]} features\")\n",
    "print(f\"y_train.csv: {len(y_train)} labels\")\n",
    "print(f\"y_test.csv: {len(y_test)} labels\")\n",
    "print(\"scaler.pkl: StandardScaler object\")\n",
    "print(\"scaling_effect.png: Visualization of scaling effect on features\")\n",
    "\n",
    "# Check if the files were created successfully\n",
    "for filename in ['X_train.csv', 'X_test.csv', 'y_train.csv', 'y_test.csv', 'scaler.pkl']:\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"{filename}: ✓ (File exists)\")\n",
    "    else:\n",
    "        print(f\"{filename}: ✗ (File does not exist)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9260202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
