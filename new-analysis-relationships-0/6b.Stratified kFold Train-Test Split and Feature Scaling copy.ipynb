{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d7d3a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Stratified K-Fold Cross Validation and Feature Scaling...\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Starting Stratified K-Fold Cross Validation and Feature Scaling...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da026011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data...\n",
      "Data loaded with headers.\n",
      "Data shape: (51613, 5)\n",
      "First few rows:\n",
      "   funding_rounds  funding_total_usd  milestones  relationships  \\\n",
      "0             3.0         39750000.0         5.0           17.0   \n",
      "1             0.0                0.0         0.0            6.0   \n",
      "2             0.0                0.0         4.0           12.0   \n",
      "3             0.0                0.0         1.0            2.0   \n",
      "4             0.0                0.0         1.0            2.0   \n",
      "\n",
      "   success_binary  \n",
      "0               0  \n",
      "1               1  \n",
      "2               1  \n",
      "3               0  \n",
      "4               0  \n",
      "\n",
      "Data information:\n",
      "Number of samples: 51613\n",
      "Number of features: 5\n",
      "Column names: ['funding_rounds', 'funding_total_usd', 'milestones', 'relationships', 'success_binary']\n",
      "\n",
      "Checking for missing values...\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Separating features and target variable...\n",
      "Using column names to identify target variable...\n",
      "Found target column: success_binary\n",
      "Features shape: (51613, 4)\n",
      "Target shape: (51613,)\n",
      "Target value counts:\n",
      "success_binary\n",
      "0    34964\n",
      "1    16649\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed data\n",
    "print(\"Loading preprocessed data...\")\n",
    "try:\n",
    "    # First try to load with headers, as this is most common\n",
    "    data = pd.read_csv('usa_final_companies_with_success_labels.csv')\n",
    "    print(\"Data loaded with headers.\")\n",
    "    print(f\"Data shape: {data.shape}\")\n",
    "    print(\"First few rows:\")\n",
    "    print(data.head())\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle other potential errors\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    raise\n",
    "\n",
    "# Display basic information about the data\n",
    "print(\"\\nData information:\")\n",
    "print(f\"Number of samples: {data.shape[0]}\")\n",
    "print(f\"Number of features: {data.shape[1]}\")\n",
    "print(f\"Column names: {list(data.columns)}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nChecking for missing values...\")\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Separate features and target variable\n",
    "print(\"\\nSeparating features and target variable...\")\n",
    "\n",
    "# Check if the data has column names\n",
    "if isinstance(data.columns[0], str) and not data.columns[0].isdigit():\n",
    "    # Data has column names\n",
    "    print(\"Using column names to identify target variable...\")\n",
    "\n",
    "    # Look for common target column names\n",
    "    target_columns = ['success_binary', 'target', 'label', 'class', 'y']\n",
    "    target_col = None\n",
    "\n",
    "    for col in target_columns:\n",
    "        if col in data.columns:\n",
    "            target_col = col\n",
    "            break\n",
    "\n",
    "    if target_col:\n",
    "        print(f\"Found target column: {target_col}\")\n",
    "        X = data.drop(columns=[target_col])\n",
    "        y = data[target_col]\n",
    "    else:\n",
    "        print(\"No standard target column found. Assuming last column is target.\")\n",
    "        X = data.iloc[:, :-1]\n",
    "        y = data.iloc[:, -1]\n",
    "else:\n",
    "    # Data doesn't have column names\n",
    "    print(\"No column names found. Assuming last column is target.\")\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target value counts:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d375629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Implementing Stratified K-Fold Cross Validation...\n",
      "\n",
      "Performing 5-fold cross-validation...\n",
      "\n",
      "Processing fold 1/5...\n",
      "Scaling features for fold 1...\n",
      "Fold 1 training set shape: (41290, 4)\n",
      "Fold 1 testing set shape: (10323, 4)\n",
      "Fold 1 training target distribution:\n",
      "success_binary\n",
      "0    0.677428\n",
      "1    0.322572\n",
      "Name: proportion, dtype: float64\n",
      "Fold 1 testing target distribution:\n",
      "success_binary\n",
      "0    0.677419\n",
      "1    0.322581\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Processing fold 2/5...\n",
      "Scaling features for fold 2...\n",
      "Fold 2 training set shape: (41290, 4)\n",
      "Fold 2 testing set shape: (10323, 4)\n",
      "Fold 2 training target distribution:\n",
      "success_binary\n",
      "0    0.677428\n",
      "1    0.322572\n",
      "Name: proportion, dtype: float64\n",
      "Fold 2 testing target distribution:\n",
      "success_binary\n",
      "0    0.677419\n",
      "1    0.322581\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Processing fold 3/5...\n",
      "Scaling features for fold 3...\n",
      "Fold 3 training set shape: (41290, 4)\n",
      "Fold 3 testing set shape: (10323, 4)\n",
      "Fold 3 training target distribution:\n",
      "success_binary\n",
      "0    0.677428\n",
      "1    0.322572\n",
      "Name: proportion, dtype: float64\n",
      "Fold 3 testing target distribution:\n",
      "success_binary\n",
      "0    0.677419\n",
      "1    0.322581\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Processing fold 4/5...\n",
      "Scaling features for fold 4...\n",
      "Fold 4 training set shape: (41291, 4)\n",
      "Fold 4 testing set shape: (10322, 4)\n",
      "Fold 4 training target distribution:\n",
      "success_binary\n",
      "0    0.677412\n",
      "1    0.322588\n",
      "Name: proportion, dtype: float64\n",
      "Fold 4 testing target distribution:\n",
      "success_binary\n",
      "0    0.677485\n",
      "1    0.322515\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Processing fold 5/5...\n",
      "Scaling features for fold 5...\n",
      "Fold 5 training set shape: (41291, 4)\n",
      "Fold 5 testing set shape: (10322, 4)\n",
      "Fold 5 training target distribution:\n",
      "success_binary\n",
      "0    0.677436\n",
      "1    0.322564\n",
      "Name: proportion, dtype: float64\n",
      "Fold 5 testing target distribution:\n",
      "success_binary\n",
      "0    0.677388\n",
      "1    0.322612\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Saving fold data...\n",
      "Saved fold 1 data\n",
      "Saved fold 2 data\n",
      "Saved fold 3 data\n",
      "Saved fold 4 data\n",
      "Saved fold 5 data\n",
      "\n",
      "Stratified K-Fold Cross Validation and Feature Scaling completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Implement stratified K-fold cross-validation\n",
    "print(\"\\nImplementing Stratified K-Fold Cross Validation...\")\n",
    "\n",
    "# Define the number of folds\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store results\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1s = []\n",
    "\n",
    "# Initialize lists to store the scaled data for each fold\n",
    "X_train_all_folds = []\n",
    "X_test_all_folds = []\n",
    "y_train_all_folds = []\n",
    "y_test_all_folds = []\n",
    "scalers = []\n",
    "\n",
    "print(f\"\\nPerforming {n_folds}-fold cross-validation...\")\n",
    "\n",
    "# Perform K-fold cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\nProcessing fold {fold+1}/{n_folds}...\")\n",
    "    \n",
    "    # Split the data for this fold\n",
    "    X_train_fold, X_test_fold = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train_fold, y_test_fold = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Scale the features\n",
    "    print(f\"Scaling features for fold {fold+1}...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "    X_test_scaled = scaler.transform(X_test_fold)\n",
    "    \n",
    "    # Convert back to DataFrame to preserve column names\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train_fold.columns)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test_fold.columns)\n",
    "    \n",
    "    # Save the fold data\n",
    "    X_train_all_folds.append(X_train_scaled)\n",
    "    X_test_all_folds.append(X_test_scaled)\n",
    "    y_train_all_folds.append(y_train_fold)\n",
    "    y_test_all_folds.append(y_test_fold)\n",
    "    scalers.append(scaler)\n",
    "    \n",
    "    # Print fold statistics\n",
    "    print(f\"Fold {fold+1} training set shape: {X_train_scaled.shape}\")\n",
    "    print(f\"Fold {fold+1} testing set shape: {X_test_scaled.shape}\")\n",
    "    print(f\"Fold {fold+1} training target distribution:\\n{y_train_fold.value_counts(normalize=True)}\")\n",
    "    print(f\"Fold {fold+1} testing target distribution:\\n{y_test_fold.value_counts(normalize=True)}\")\n",
    "\n",
    "# Save all fold data\n",
    "output_dir = '/Users/aminosaurier/Downloads/spring_2025_startup_survival/new-analysis-relationships-0/'\n",
    "\n",
    "print(\"\\nSaving fold data...\")\n",
    "for fold in range(n_folds):\n",
    "    # Save X_train for this fold\n",
    "    X_train_all_folds[fold].to_csv(f'{output_dir}X_train_fold{fold+1}.csv', index=False)\n",
    "    \n",
    "    # Save X_test for this fold\n",
    "    X_test_all_folds[fold].to_csv(f'{output_dir}X_test_fold{fold+1}.csv', index=False)\n",
    "    \n",
    "    # Save y_train for this fold\n",
    "    if isinstance(y_train_all_folds[fold], pd.Series):\n",
    "        y_train_all_folds[fold].to_csv(f'{output_dir}y_train_fold{fold+1}.csv', index=False, header=True)\n",
    "    else:\n",
    "        pd.DataFrame(y_train_all_folds[fold]).to_csv(f'{output_dir}y_train_fold{fold+1}.csv', index=False, header=False)\n",
    "    \n",
    "    # Save y_test for this fold\n",
    "    if isinstance(y_test_all_folds[fold], pd.Series):\n",
    "        y_test_all_folds[fold].to_csv(f'{output_dir}y_test_fold{fold+1}.csv', index=False, header=True)\n",
    "    else:\n",
    "        pd.DataFrame(y_test_all_folds[fold]).to_csv(f'{output_dir}y_test_fold{fold+1}.csv', index=False, header=False)\n",
    "    \n",
    "    # Save the scaler for this fold\n",
    "    with open(f'{output_dir}scaler_fold{fold+1}.pkl', 'wb') as f:\n",
    "        pickle.dump(scalers[fold], f)\n",
    "        \n",
    "    print(f\"Saved fold {fold+1} data\")\n",
    "\n",
    "print(\"\\nStratified K-Fold Cross Validation and Feature Scaling completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ff1ebde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of outputs:\n",
      "\n",
      "Fold 1:\n",
      "X_train_fold1.csv: 41290 samples, 4 features\n",
      "X_test_fold1.csv: 10323 samples, 4 features\n",
      "y_train_fold1.csv: 41290 labels\n",
      "y_test_fold1.csv: 10323 labels\n",
      "scaler_fold1.pkl: StandardScaler object\n",
      "\n",
      "Fold 2:\n",
      "X_train_fold2.csv: 41290 samples, 4 features\n",
      "X_test_fold2.csv: 10323 samples, 4 features\n",
      "y_train_fold2.csv: 41290 labels\n",
      "y_test_fold2.csv: 10323 labels\n",
      "scaler_fold2.pkl: StandardScaler object\n",
      "\n",
      "Fold 3:\n",
      "X_train_fold3.csv: 41290 samples, 4 features\n",
      "X_test_fold3.csv: 10323 samples, 4 features\n",
      "y_train_fold3.csv: 41290 labels\n",
      "y_test_fold3.csv: 10323 labels\n",
      "scaler_fold3.pkl: StandardScaler object\n",
      "\n",
      "Fold 4:\n",
      "X_train_fold4.csv: 41291 samples, 4 features\n",
      "X_test_fold4.csv: 10322 samples, 4 features\n",
      "y_train_fold4.csv: 41291 labels\n",
      "y_test_fold4.csv: 10322 labels\n",
      "scaler_fold4.pkl: StandardScaler object\n",
      "\n",
      "Fold 5:\n",
      "X_train_fold5.csv: 41291 samples, 4 features\n",
      "X_test_fold5.csv: 10322 samples, 4 features\n",
      "y_train_fold5.csv: 41291 labels\n",
      "y_test_fold5.csv: 10322 labels\n",
      "scaler_fold5.pkl: StandardScaler object\n",
      "\n",
      "Saved visualization of feature distributions to feature_distributions_across_folds.png\n",
      "\n",
      "Checking if files were created successfully:\n",
      "X_train_fold1.csv: ✓ (File exists)\n",
      "X_test_fold1.csv: ✓ (File exists)\n",
      "y_train_fold1.csv: ✓ (File exists)\n",
      "y_test_fold1.csv: ✓ (File exists)\n",
      "scaler_fold1.pkl: ✓ (File exists)\n",
      "X_train_fold2.csv: ✓ (File exists)\n",
      "X_test_fold2.csv: ✓ (File exists)\n",
      "y_train_fold2.csv: ✓ (File exists)\n",
      "y_test_fold2.csv: ✓ (File exists)\n",
      "scaler_fold2.pkl: ✓ (File exists)\n",
      "X_train_fold3.csv: ✓ (File exists)\n",
      "X_test_fold3.csv: ✓ (File exists)\n",
      "y_train_fold3.csv: ✓ (File exists)\n",
      "y_test_fold3.csv: ✓ (File exists)\n",
      "scaler_fold3.pkl: ✓ (File exists)\n",
      "X_train_fold4.csv: ✓ (File exists)\n",
      "X_test_fold4.csv: ✓ (File exists)\n",
      "y_train_fold4.csv: ✓ (File exists)\n",
      "y_test_fold4.csv: ✓ (File exists)\n",
      "scaler_fold4.pkl: ✓ (File exists)\n",
      "X_train_fold5.csv: ✓ (File exists)\n",
      "X_test_fold5.csv: ✓ (File exists)\n",
      "y_train_fold5.csv: ✓ (File exists)\n",
      "y_test_fold5.csv: ✓ (File exists)\n",
      "scaler_fold5.pkl: ✓ (File exists)\n"
     ]
    }
   ],
   "source": [
    "# Print summary of the outputs\n",
    "print(\"\\nSummary of outputs:\")\n",
    "for fold in range(n_folds):\n",
    "    print(f\"\\nFold {fold+1}:\")\n",
    "    print(f\"X_train_fold{fold+1}.csv: {X_train_all_folds[fold].shape[0]} samples, {X_train_all_folds[fold].shape[1]} features\")\n",
    "    print(f\"X_test_fold{fold+1}.csv: {X_test_all_folds[fold].shape[0]} samples, {X_test_all_folds[fold].shape[1]} features\")\n",
    "    print(f\"y_train_fold{fold+1}.csv: {len(y_train_all_folds[fold])} labels\")\n",
    "    print(f\"y_test_fold{fold+1}.csv: {len(y_test_all_folds[fold])} labels\")\n",
    "    print(f\"scaler_fold{fold+1}.pkl: StandardScaler object\")\n",
    "\n",
    "# Create a visualization of the feature distributions across folds\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Select a few features to visualize (first 5)\n",
    "features_to_plot = min(5, X.shape[1])\n",
    "feature_names = list(X.columns[:features_to_plot])\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    for fold in range(n_folds):\n",
    "        plt.hist(X_test_all_folds[fold][feature], alpha=0.5, bins=20, label=f'Fold {fold+1}')\n",
    "    plt.title(f'Distribution of {feature} across folds')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}feature_distributions_across_folds.png')\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nSaved visualization of feature distributions to feature_distributions_across_folds.png\")\n",
    "\n",
    "# Check if the files were created successfully\n",
    "print(\"\\nChecking if files were created successfully:\")\n",
    "for fold in range(n_folds):\n",
    "    for filename in [f'X_train_fold{fold+1}.csv', f'X_test_fold{fold+1}.csv', \n",
    "                     f'y_train_fold{fold+1}.csv', f'y_test_fold{fold+1}.csv', \n",
    "                     f'scaler_fold{fold+1}.pkl']:\n",
    "        full_path = os.path.join(output_dir, filename)\n",
    "        if os.path.exists(full_path):\n",
    "            print(f\"{filename}: ✓ (File exists)\")\n",
    "        else:\n",
    "            print(f\"{filename}: ✗ (File does not exist)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f3626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a 5-fold stratified cross-validation setup (you can adjust n_folds as needed)\n",
    "# Maintains the data splitting approach from your original code\n",
    "# Scales features independently for each fold\n",
    "# Saves the training/testing data and scalers for each fold separately\n",
    "# Creates a visualization of feature distributions across folds\n",
    "# Provides detailed summary statistics for each fold\n",
    "# Using stratified K-fold cross-validation will give you more reliable performance estimates compared to a single train-test split, especially for imbalanced datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
